{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adrig\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "SEED = 234523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/train.csv', index_col='train_idx')\n",
    "df.drop(['label_text'], inplace=True, axis='columns')\n",
    "train, validation = train_test_split(df, test_size=0.25, random_state=SEED)\n",
    "\n",
    "test = pd.read_csv('./dataset/test.csv')\n",
    "\n",
    "dataset = DatasetDict()\n",
    "dataset['train'] = Dataset.from_pandas(train)\n",
    "dataset['validation'] = Dataset.from_pandas(validation)\n",
    "dataset['test'] = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaModel: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MODEL_NAME = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "pretrained_model = AutoModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    tokens = tokenizer(batch['text'], padding='max_length', truncation=True, max_length=512)\n",
    "    batch['input_ids'], batch['attention_mask'] = tokens['input_ids'], tokens['attention_mask']\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(tokenize)\n",
    "\n",
    "dataset['train'].set_format('pt', columns=['input_ids', 'attention_mask', 'label'])\n",
    "dataset['validation'].set_format('pt', columns=['input_ids', 'attention_mask', 'label'])\n",
    "dataset['test'].set_format('pt', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "dataset['train'] = dataset['train'].remove_columns(['text', 'train_idx'])\n",
    "dataset['validation'] = dataset['validation'].remove_columns(['text', 'train_idx'])\n",
    "dataset['test'] = dataset['test'].remove_columns(['text', 'test_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentimentAnalysis, self).__init__()\n",
    "        self.roberta = pretrained_model\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.activation1 = nn.GELU()\n",
    "        self.output = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.roberta(input_ids, attention_mask).pooler_output\n",
    "        x = self.activation1(self.fc1(x))\n",
    "        x = torch.softmax(self.output(x), dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "STEPS_PER_EPOCH = len(dataset['train']) // BATCH_SIZE\n",
    "\n",
    "train_loader = DataLoader(dataset['train'], batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(dataset['validation'], batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset['test'], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(b_idx, perc_steps=25):\n",
    "    perc_epoch = int(b_idx / STEPS_PER_EPOCH * perc_steps)\n",
    "    perc_left = perc_steps - perc_epoch\n",
    "    return perc_epoch, perc_left\n",
    "\n",
    "def train_metrics(b_idx, outputs, labels, y_true, y_pred):\n",
    "    if b_idx == 0: \n",
    "        y_true = labels.detach().cpu().numpy()\n",
    "        y_pred = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "    else: \n",
    "        y_true = np.concatenate((y_true, labels.detach().cpu().numpy()))\n",
    "        y_pred = np.concatenate((y_pred, torch.argmax(outputs, dim=1).detach().cpu().numpy()))\n",
    "    \n",
    "    return f1_score(y_true, y_pred), y_true, y_pred\n",
    "\n",
    "def compute_eta(b_idx, start_batch, batch_times):\n",
    "    batch_times.append(time.time() - start_batch)\n",
    "    if b_idx == 0: batch_avg_time = batch_times[0]\n",
    "    else: \n",
    "        batch_times = batch_times[-10:]\n",
    "        batch_avg_time = sum(batch_times) / len(batch_times)\n",
    "    \n",
    "    seconds_left = (STEPS_PER_EPOCH - b_idx) * batch_avg_time\n",
    "    if seconds_left > 60: eta = time.strftime('%M:%S', time.gmtime(seconds_left))\n",
    "    else: eta = f'{seconds_left:.2f} s'\n",
    "\n",
    "    return eta, batch_times\n",
    "\n",
    "def validation_step(model):\n",
    "    model.eval()\n",
    "    y_pred, y_true = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in validation_loader:\n",
    "            input_ids, attention_masks = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
    "            labels = batch['label']\n",
    "\n",
    "            outputs = model(input_ids, attention_masks)\n",
    "            batch_pred = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "            y_pred.append(batch_pred)\n",
    "\n",
    "            y_true.append(labels.numpy())\n",
    "            \n",
    "    y_pred, y_true = np.concatenate(y_pred), np.concatenate(y_true)\n",
    "    val_f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return val_f1\n",
    "\n",
    "def time_epoch(start_epoch):\n",
    "    return f'{int(time.time() - start_epoch)} s'\n",
    "\n",
    "def save_model(model, exp):\n",
    "    torch.save(model.state_dict(), f'./models/{exp}.pt')\n",
    "\n",
    "def epoch_status(b_idx, outputs, labels, start_batch, model, loss, start_epoch, y_true, y_pred, batch_times, best_val_f1, exp):\n",
    "    perc_epoch, perc_left = progress_bar(b_idx)\n",
    "    accumulative_f1, y_true, y_pred = train_metrics(b_idx, outputs, labels, y_true, y_pred)\n",
    "    eta, batch_times = compute_eta(b_idx, start_batch, batch_times)\n",
    "\n",
    "    val_f1 = False\n",
    "    if b_idx == STEPS_PER_EPOCH:\n",
    "        val_f1 = validation_step(model)\n",
    "        eta = time_epoch(start_epoch)\n",
    "        if val_f1 > best_val_f1:\n",
    "            save_model(model, exp)\n",
    "            best_val_f1 = val_f1\n",
    "\n",
    "    print(f'{b_idx}/{STEPS_PER_EPOCH}\\t[{\"=\" * perc_epoch}>{\".\" * perc_left}] - ETA: {eta} - loss: {loss.item():.4f} - f1: {accumulative_f1:.4f}{\"\" if not val_f1 else f\" - val_f1: {val_f1:.4f}\"}', end='\\r')\n",
    "    return batch_times, y_true, y_pred, best_val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs=10, experiment=str(time.time())):\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_val_f1 = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        start_epoch = time.time()\n",
    "        batch_times = [] #contains the times that each batch has lasted\n",
    "        y_true, y_pred = [], [] #accumulates the predictions for each batch\n",
    "\n",
    "        for b_idx, batch in enumerate(train_loader):\n",
    "            start_batch = time.time()\n",
    "\n",
    "            input_ids, attention_masks = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(input_ids, attention_masks)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_times, y_true, y_pred, best_val_f1 = epoch_status(b_idx, outputs, labels, start_batch, model, loss, start_epoch, y_true, y_pred, batch_times, best_val_f1, experiment)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "565/565\t[=========================>] - ETA: 82 s - loss: 0.3198 - f1: 0.8996 - val_f1: 0.9056\r"
     ]
    }
   ],
   "source": [
    "model = SentimentAnalysis()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=1e-5,\n",
    "    amsgrad=True,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "exp = 'testing'\n",
    "model = train(\n",
    "    model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    epochs=1,\n",
    "    experiment=exp\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
